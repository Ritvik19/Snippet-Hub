{"Title":{"0":"AJAX and JSON","1":"ANN","2":"Apply Mapping","3":"CNN (text)","4":"CSS Variables","5":"Continuous to Categorical","6":"Custom Scroll Bar","7":"Deal with Large Numbers","8":"Device Breakpoints","9":"Difference Between Rows","10":"Directory Manipulations","11":"Directory Walk","12":"Docstring","13":"Download a file","14":"Dynamic Attributes","15":"Editable HTML element","16":"Equal Height Columns","17":"Eval()","18":"Exploding a List","19":"Filtering","20":"Flatten a list","21":"Function Annotations","22":"Generate Secret Key","23":"IgnoreWarnings","24":"Image Shadow","25":"List Filter","26":"Modules from Directory","27":"Most Common Words","28":"Multiple files single 'with'","29":"Pandas Display Settings","30":"Password in command line","31":"RNN (text)","32":"Read GET Data","33":"SettingWithCopyWarning","34":"Shebang","35":"Smooth Scrolling","36":"Split in Multiple Columns","37":"Stopwords","38":"Text Preprocessing","39":"TimeStamp","40":"Tracking Loops","41":"Trim in JavaScript","42":"Try Else","43":"Unpacking","44":"VADER Sentiment Analysis","45":"Webscraping","46":"Word Cloud","47":"XML Parsing","48":"all() and any()","49":"collections.Counter()","50":"collections.OrderedDict()","51":"collections.defalutdict()","52":"collections.deque()","53":"collections.namedtuple()","54":"is vs ==","55":"itertools.combinations()","56":"itertools.permutations()","57":"itertools.product()","58":"re.findall()","59":"re.group()"},"Description":{"0":"(javascript) (web)","1":"(python)","2":"To a DataFrame using Dictionary (python)","3":"(python)","4":"(web)","5":"(pandas dataframe) (python)","6":"(web)","7":"(python)","8":"(css media-queries) (web)","9":"(Pandas DataFrame) (python)","10":"(python)","11":"(python)","12":"(python)","13":"(python)","14":"(python)","15":"(html) (web)","16":"(css) (web)","17":"(python)","18":"(pandas dataframe) (python)","19":"(web)","20":"(python)","21":"(python)","22":"(python)","23":"(python)","24":"(web)","25":"(web)","26":"(python)","27":"In a DataFrame (python)","28":"(python)","29":"(python)","30":"(python)","31":"(python)","32":"(javascript) (web)","33":"(pandas) (python)","34":"Shebang line for anaconda virtual environments (python)","35":"(css jquery) (web)","36":"(pandas dataframe) (python)","37":"List of Stopwords(text)","38":"(python)","39":"(python)","40":"(python)","41":"(web)","42":"(python)","43":"(python)","44":"(python)","45":"(python)","46":"(python)","47":"(python)","48":"(python)","49":"(python)","50":"(python)","51":"(python)","52":"(python)","53":"(python)","54":"(python)","55":"(python)","56":"(python)","57":"(python)","58":"(python)","59":"(python)"},"Code":{"0":"function loadCode(p, q, e)\n{\n  var xhttp = new XMLHttpRequest();\n  var filepath = '..\/..\/..'\n  console.log(filepath)\n  xhttp.onreadystatechange = function() {\n    if (this.readyState == 4 && this.status == 200) {\n     var dataObj = JSON.parse(this.responseText);\n     col1 = dataObj['col1']\n     content = ''\n     var i = 0;\n     while(typeof program_name[i] !== \"undefined\")\n     {\n        content += col1[i]+'\n'\n     }\n     document.getElementById(\"demo\").innerHTML = content;\n    }\n  };\n  xhttp.open(\"GET\", filepath, true);\n  xhttp.send();\n}","1":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers\n# optimizers.SGD()\n# optimizers.RMSProp()\n# optimizers.Adagrad()\n# optimizers.Adadelta()\n# optimizers.Adam()\n\nes = EarlyStopping(monitor='loss', mode='min', verbose=1)\nfilepath = \"model.h5\"\nckpt = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\ndef build_network():\n    model = Sequential()\n    model.add(Dense(160,input_dim=40, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(320, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(365, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(125, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(25, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=, metrics=['accuracy'])\n    model.summary()\n    return model\n\nmodel = build_network()\n\nmodel.fit(scaled_data, train_label[0], validation_split=0.3, epochs=25, callbacks=[es, ckpt])\n\n\nfrom keras.models import load_model\nnew_model = load_model(\"model.h5\")","2":"mapping = {'male':0, 'female':1}\n\n\ncols = ['A', 'B', 'C']\ndf[cols] = df[cols].applymap(mapping.get())","3":"from keras.models import Sequential\nfrom keras.laeyrs import Dense, Dropout, Flatten, Embedding, Convolution1D, MaxPooling1D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import optimizers\n# optimizers.SGD()\n# optimizers.RMSProp()\n# optimizers.Adagrad()\n# optimizers.Adadelta()\n# optimizers.Adam()\n\nvocabulary_size = 7500\npad_length = 1000\ntokenizer = Tokenizer(num_words= vocabulary_size)\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\npadded_sequences = pad_sequences(sequences, maxlen=pad_length)\n\nes = EarlyStopping(monitor='loss', mode='min', verbose=1)\nfilepath = \"model.h5\"\nckpt = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\ndef build_network():\n    model = Sequential()\n    model.add(Embedding(vocabulary_size, 1024, input_length=pad_length))\n    model.add(Convolution1D(1024, kernel_size=5, activation='tanh', strides=2))\n    model.add(MaxPooling1D(pool_size=5))\n    model.add(Dense(160,input_dim=40, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(320, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(365, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(125, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(25, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=, metrics=['accuracy'])\n    model.summary()\n    return model\n\nmodel = build_network()\n\nmodel.fit(scaled_data, train_label[0], validation_split=0.3, epochs=25, callbacks=[es, ckpt])\n\n\nfrom keras.models import load_model\nnew_model = load_model(\"model.h5\")","4":":root {\n  --main-bg-color: coral; \n}\n\n#div1 {\n  background-color: var(--main-bg-color); \n}","5":"df['age_groups'] = pd.cut(df.age, bins=[0, 18, 65, 99], labels=['child', 'adult', 'elderly'])\n\n# 0 to 18 -> 'child'\n# 18 to 65 -> 'adult'\n# 65 to 99 -> 'elderly'","6":"\/* width *\/\n::-webkit-scrollbar {\n  width: 10px;\n}\n\n\/* Track *\/\n::-webkit-scrollbar-track {\n  background: #f1f1f1; \n}\n\n\/* Handle *\/\n::-webkit-scrollbar-thumb {\n  background: #888; \n}\n\n\/* Handle on hover *\/\n::-webkit-scrollbar-thumb:hover {\n  background: #555; \n}","7":"num1 = 100_000_000_000  # Visually chunk large numbers\nnum2 =   1_000_000_000  # without affecting the functionality\ntotal = num1 + num2\nprint(f'{total:,}')     # 101,000,000,000","8":"\/* Extra small devices (phones, 600px and down) *\/\n@media only screen and (max-width: 600px) {...}\n\n\/* Small devices (portrait tablets and large phones, 600px and up) *\/\n@media only screen and (min-width: 600px) {...}\n\n\/* Medium devices (landscape tablets, 768px and up) *\/\n@media only screen and (min-width: 768px) {...}\n\n\/* Large devices (laptops\/desktops, 992px and up) *\/\n@media only screen and (min-width: 992px) {...}\n\n\/* Extra large devices (large laptops and desktops, 1200px and up) *\/\n@media only screen and (min-width: 1200px) {...}","9":"df['Change'] = df.col.diff()\ndf['Percent Change'] = df.col.pct_change()*100\ndf.style.format({'Percent Change':'{:.2f}%'})","10":"# Current working directory\nos.getcwd()\n\n# Change the CWD\nos.chdir(PATH)\n\n# Delete any directory\nos.rmdir(PATH)\n\n# Create a new directory\nos.mkdir(PATH)\n\n# Rename a directory\nos.rename(OLD, NEW)\n\n# Delete entire directory tree\nshutil.rmtree(PATH)\n\n# Copy entire directory tree\nshutil.copytree(SRC, DST)\n\n# Move file or directory\nshutil.move(SRC, DST)","11":"import os\n\nfor folderName, subfolders, filenames in os.walk('DIRECTORY'):\n    print('The current folder is ' + folderName)\n\n    for subfolder in subfolders:\n        print('SUBFOLDER OF ' + folderName + ': ' + subfolder)\n    for filename in filenames:\n        print('FILE INSIDE ' + folderName + ': '+ filename)\n\n    print('')","12":"def add(a, b):\n   \"\"\"this function takes 2 numbers and return their sum\"\"\"\n   return a+b\n\nprint(add.__doc__)\n\n# Output:\n# this function takes 2 numbers and return their sum\n\n\nclass Car():\n   \"\"\"this is a class\"\"\"\n   pass\n\nprint(Car.__doc__)\n\n# Output:\n# this is a class","13":"import requests\nres = requests.get('file\/url')\nres.raise_for_status()\nwith open('file.txt', 'wb') as f:\n    for chunk in res.iter_content(100000):\n        f.write(chunk)","14":"class Person():\n    pass\n\nperson = Person()\n\np_key = 'name'\np_value = 'Ritvik'\n\n\nsetattr(person, p_key, p_value)\nname = getattr(person, p_key)","15":"<div contenteditable='true'>This div is editable<\/div>","16":".col-container {\n    display: table; \/* Make the container element behave like a table *\/\n    width: 100%; \/* Set full-width to expand the whole page *\/\n}\n\n.col {\n    display: table-cell; \/* Make elements inside the container behave like table cells *\/\n}\n\n\n\/* If the browser window is smaller than 600px, make the columns stack on top of each other *\/\n@media only screen and (max-width: 600px) {\n  .col {\n    display: block;\n    width: 100%;\n  }\n}","17":"# it is a builtin function that allows us to\n# execute arbitrry strings in python\n\nadd = \"1+5+6\"\ndisplay = \"print('Hello')\"\n\nprint (eval(add))  # 12\neval(display)      # Hello","18":">>> df = pd.DataFrame({'sandwich':  ['PB&J', 'BLT', 'cheese'],\n      'ingredients':[['peanut butter', 'jelly'],\n                    ['bacon', 'lettuce', 'tomato'],\n                    ['swiss cheese']]})\n>>> df\n    sandwich    ingredients\n0   PB&J        [peanut butter, jelly]\n1   BLT         [bacon, lettuce, tomato]\n2   cheese      [swiss cheese]\n>>> df.explode('ingredients')\n    sandwich    ingredients\n0   PB&J        peanut butter\n0   PB&J        jelly\n1   BLT         bacon\n1   BLT         lettuce\n1   BLT         tomato\n2   cheese      swiss cheese","19":"<h2>PORTFOLIO<\/h2>\n<div id=\"myBtnContainer\">\n  <button class=\"btn active\" onclick=\"filterSelection('all')\"> Show all<\/button>\n  <button class=\"btn\" onclick=\"filterSelection('nature')\"> Nature<\/button>\n  <button class=\"btn\" onclick=\"filterSelection('cars')\"> Cars<\/button>\n  <button class=\"btn\" onclick=\"filterSelection('people')\"> People<\/button>\n<\/div>\n\n<!-- Portfolio Gallery Grid -->\n<div class=\"row\">\n  <div class=\"column nature\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/mountains.jpg\" alt=\"Mountains\" style=\"width:100%\">\n      <h4>Mountains<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n  <div class=\"column nature\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/lights.jpg\" alt=\"Lights\" style=\"width:100%\">\n      <h4>Lights<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n  <div class=\"column nature\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/nature.jpg\" alt=\"Nature\" style=\"width:100%\">\n      <h4>Forest<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n\n  <div class=\"column cars\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/cars1.jpg\" alt=\"Car\" style=\"width:100%\">\n      <h4>Retro<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n  <div class=\"column cars\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/cars2.jpg\" alt=\"Car\" style=\"width:100%\">\n      <h4>Fast<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n  <div class=\"column cars\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/cars3.jpg\" alt=\"Car\" style=\"width:100%\">\n      <h4>Classic<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n\n  <div class=\"column people\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/people1.jpg\" alt=\"People\" style=\"width:100%\">\n      <h4>Girl<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n  <div class=\"column people\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/people2.jpg\" alt=\"People\" style=\"width:100%\">\n      <h4>Man<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n  <div class=\"column people\">\n    <div class=\"content\">\n      <img src=\"\/w3images\/people3.jpg\" alt=\"People\" style=\"width:100%\">\n      <h4>Woman<\/h4>\n      <p>Lorem ipsum dolor..<\/p>\n    <\/div>\n  <\/div>\n<!-- END GRID -->\n<\/div>\n\n\/* Center website *\/\n.main {\n  max-width: 1000px;\n  margin: auto;\n}\n\nh1 {\n  font-size: 50px;\n  word-break: break-all;\n}\n\n.row {\n  margin: 8px -16px;\n}\n\n\/* Add padding BETWEEN each column (if you want) *\/\n.row,\n.row > .column {\n  padding: 8px;\n}\n\n\/* Create three equal columns that floats next to each other *\/\n.column {\n  float: left;\n  width: 33.33%;\n  display: none; \/* Hide columns by default *\/\n}\n\n\/* Clear floats after rows *\/\n.row:after {\n  content: \"\";\n  display: table;\n  clear: both;\n}\n\n\/* Content *\/\n.content {\n  background-color: white;\n  padding: 10px;\n}\n\n\/* The \"show\" class is added to the filtered elements *\/\n.show {\n  display: block;\n}\n\n\/* Style the buttons *\/\n.btn {\n  border: none;\n  outline: none;\n  padding: 12px 16px;\n  background-color: white;\n  cursor: pointer;\n}\n\n\/* Add a grey background color on mouse-over *\/\n.btn:hover {\n  background-color: #ddd;\n}\n\n\/* Add a dark background color to the active button *\/\n.btn.active {\n  background-color: #666;\n   color: white;\n}\n\nfilterSelection(\"all\") \/\/ Execute the function and show all columns\nfunction filterSelection(c) {\n  var x, i;\n  x = document.getElementsByClassName(\"column\");\n  if (c == \"all\") c = \"\";\n  \/\/ Add the \"show\" class (display:block) to the filtered elements, and remove the \"show\" class from the elements that are not selected\n  for (i = 0; i < x.length; i++) {\n    w3RemoveClass(x[i], \"show\");\n    if (x[i].className.indexOf(c) > -1) w3AddClass(x[i], \"show\");\n  }\n}\n\n\/\/ Show filtered elements\nfunction w3AddClass(element, name) {\n  var i, arr1, arr2;\n  arr1 = element.className.split(\" \");\n  arr2 = name.split(\" \");\n  for (i = 0; i < arr2.length; i++) {\n    if (arr1.indexOf(arr2[i]) == -1) {\n      element.className += \" \" + arr2[i];\n    }\n  }\n}\n\n\/\/ Hide elements that are not selected\nfunction w3RemoveClass(element, name) {\n  var i, arr1, arr2;\n  arr1 = element.className.split(\" \");\n  arr2 = name.split(\" \");\n  for (i = 0; i < arr2.length; i++) {\n    while (arr1.indexOf(arr2[i]) > -1) {\n      arr1.splice(arr1.indexOf(arr2[i]), 1);\n    }\n  }\n  element.className = arr1.join(\" \");\n}\n\n\/\/ Add active class to the current button (highlight it)\nvar btnContainer = document.getElementById(\"myBtnContainer\");\nvar btns = btnContainer.getElementsByClassName(\"btn\");\nfor (var i = 0; i < btns.length; i++) {\n  btns[i].addEventListener(\"click\", function(){\n    var current = document.getElementsByClassName(\"active\");\n    current[0].className = current[0].className.replace(\" active\", \"\");\n    this.className += \" active\";\n  });\n}","20":"flat_list = [item for sublist in l for item in sublist]","21":"def power(a: int, b:int) ->int:\n    return a**b\n\nprint(power.__annotations__)\n\n# Output:\n# {'a': <class 'int'>, 'b': <class 'int'>, 'return': <class 'int'>}","22":">>> import secrets\n>>> secrets.token_hex(16)\n'79e9d3b5d183b6e620e3776f77d95f4b'","23":"import warnings\r\nwarnings.filterwarnings(\"ignore\")","24":"filter: drop-shadow(0 15px 17px rgba(38,38,143,.37));","25":"function listFilter(inputEl, listEl, element) {\n    var input, filter, ul, li, a, i, txtValue;\n    input = document.getElementById(inputEl);\n    filter = input.value.toUpperCase();\n    ul = document.getElementById(listEl);\n    li = ul.getElementsByTagName(\"li\");\n    for (i = 0; i < li.length; i++) {\n        a = li[i].getElementsByTagName(element)[0];\n        txtValue = a.textContent || a.innerText;\n        if (txtValue.toUpperCase().indexOf(filter) > -1) {\n            li[i].style.display = \"\";\n        } else {\n            li[i].style.display = \"none\";\n        }\n    }\n}","26":"import sys, os\nsys.path.append(os.path.join(sys.path[0], 'modules'))\n\nimport module1","27":"pd.Series(' '.join(df['text']).split()).value_counts()[:n]","28":"with \\\n    open('a.txt') as a,\\\n    open('b.txt', 'w') as b:\n    for line in a:\n        b.write(line)","29":"pd.options.display.max_columns = 10\npd.options.display.max_colwidth = -1","30":"from getpass import getpass\nusername = input('Enter Username...')   # User Input is displayed in the commandline\npassword = getpass('Enter Password...') # User Input is not displayed in the commandline","31":"from keras.models import Sequential\nfrom keras.laeyrs import Dense, Dropout, LSTM, Embedding\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import optimizers\n# optimizers.SGD()\n# optimizers.RMSProp()\n# optimizers.Adagrad()\n# optimizers.Adadelta()\n# optimizers.Adam()\n\nvocabulary_size = 7500\npad_length = 1000\ntokenizer = Tokenizer(num_words= vocabulary_size)\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\npadded_sequences = pad_sequences(sequences, maxlen=pad_length)\n\nes = EarlyStopping(monitor='loss', mode='min', verbose=1)\nfilepath = \"model.h5\"\nckpt = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\ndef build_network():\n    model = Sequential()\n    model.add(Embedding(vocabulary_size, 1024, input_length=pad_length))\n    model.add(LSTM(1024, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(160,input_dim=40, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(320, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(365, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(125, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(25, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=, metrics=['accuracy'])\n    model.summary()\n    return model\n\nmodel = build_network()\n\nmodel.fit(scaled_data, train_label[0], validation_split=0.3, epochs=25, callbacks=[es, ckpt])\n\n\nfrom keras.models import load_model\nnew_model = load_model(\"model.h5\")","32":"\/\/ www.example.com?q=something\n\nvar params = new URLSearchParams(location.search);\nvar q = params.get('q')\nif (q == null){\n\n}else if (q == 'something'){\n\n}else{\n\n}","33":"# instead of \ndf[df['gender'] == 'F']['gender'] = 'Female'\n# do\ndf.loc[df['gender'] == 'F', 'gender'] = 'Female'","34":"#!D:\\Users\\Ritvik\\Anaconda3\\envs\\datascience\\python.exe","35":"html {\n  scroll-behavior: smooth;\n}\n\n\/\/For browsers that do not support the scroll-behavior property\n\n$(document).ready(function(){\n  $(\"a\").on('click', function(event) {\n    if (this.hash !== \"\") {\n      event.preventDefault();\n      var hash = this.hash;\n      $('html, body').animate({\n        scrollTop: $(hash).offset().top\n      }, 800, function(){\n        window.location.hash = hash;\n      });\n    }\n  });\n});","36":"df[['fisrt', 'middle', 'last']] = df.name.str.split(' ', expand=True)","37":"a\nabout\nabove\nacross\nafter\nafterwards\nagain\nagainst\nall\nalmost\nalone\nalong\nalready\nalso\nalthough\nalways\nam\namong\namongst\namoungst\namount\nan\nand\nanother\nany\nanyhow\nanyone\nanything\nanyway\nanywhere\nare\naround\nas\nat\nback\nbe\nbecame\nbecause\nbecome\nbecomes\nbecoming\nbeen\nbefore\nbeforehand\nbehind\nbeing\nbelow\nbeside\nbesides\nbetween\nbeyond\nbill\nboth\nbottom\nbut\nby\ncall\ncan\ncannot\ncant\nco\ncomputer\ncon\ncould\ncouldnt\ncry\nde\ndescribe\ndetail\ndo\ndone\ndown\ndue\nduring\neach\neg\neight\neither\neleven\nelse\nelsewhere\nempty\nenough\netc\neven\never\nevery\neveryone\neverything\neverywhere\nexcept\nfew\nfifteen\nfify\nfill\nfind\nfire\nfirst\nfive\nfor\nformer\nformerly\nforty\nfound\nfour\nfrom\nfront\nfull\nfurther\nget\ngive\ngo\nhad\nhas\nhasnt\nhave\nhe\nhence\nher\nhere\nhereafter\nhereby\nherein\nhereupon\nhers\nherse\"\nhim\nhimse\"\nhis\nhow\nhowever\nhundred\ni\nie\nif\nin\ninc\nindeed\ninterest\ninto\nis\nit\nits\nitse\"\nkeep\nlast\nlatter\nlatterly\nleast\nless\nltd\nmade\nmany\nmay\nme\nmeanwhile\nmight\nmill\nmine\nmore\nmoreover\nmost\nmostly\nmove\nmuch\nmust\nmy\nmyse\"\nname\nnamely\nneither\nnever\nnevertheless\nnext\nnine\nno\nnobody\nnone\nnoone\nnor\nnot\nnothing\nnow\nnowhere\nof\noff\noften\non\nonce\none\nonly\nonto\nor\nother\nothers\notherwise\nour\nours\nourselves\nout\nover\nown\npart\nper\nperhaps\nplease\nput\nrather\nre\nsame\nsee\nseem\nseemed\nseeming\nseems\nserious\nseveral\nshe\nshould\nshow\nside\nsince\nsincere\nsix\nsixty\nso\nsome\nsomehow\nsomeone\nsomething\nsometime\nsometimes\nsomewhere\nstill\nsuch\nsystem\ntake\nten\nthan\nthat\nthe\ntheir\nthem\nthemselves\nthen\nthence\nthere\nthereafter\nthereby\ntherefore\ntherein\nthereupon\nthese\nthey\nthick\nthin\nthird\nthis\nthose\nthough\nthree\nthrough\nthroughout\nthru\nthus\nto\ntogether\ntoo\ntop\ntoward\ntowards\ntwelve\ntwenty\ntwo\nun\nunder\nuntil\nup\nupon\nus\nvery\nvia\nwas\nwe\nwell\nwere\nwhat\nwhatever\nwhen\nwhence\nwhenever\nwhere\nwhereafter\nwhereas\nwhereby\nwherein\nwhereupon\nwherever\nwhether\nwhich\nwhile\nwhither\nwho\nwhoever\nwhole\nwhom\nwhose\nwhy\nwill\nwith\nwithin\nwithout\nwould\nyet\nyou\nyour\nyours\nyourself\nyourselves\nwhom\nm\ncouldn't\nuntil\nduring\nunder\nwasn\nboth\nout\ndidn\nbefore\naren't\nweren\nwhy\neach\nmightn\ndoesn\nbelow\nshould\nhers\nherself\nwho\ntoo\nmost\nand\nso\nabout\nshould've\nme\nyou'll\nno\nup\nshouldn\ncan\noff\nthan\njust\nonce\nain\nisn\nwon't\nthat'll\nthose\ndon\nhadn't\nisn't\nwhich\nshouldn't\nto\nthemselves\nyourself\nwas\non\nother\no\nhad\nher\nourselves\nmightn't\nhe\ndoes\nany\nyour\nthese\ndoing\nan\nby\nthrough\nwe\nfrom\nmy\nits\nit\nhaven\nma\nhasn't\nbeing\nve\nsome\nshan't\nover\nmustn't\nhimself\ntheirs\nwhere\nif\nmyself\ndo\ndon't\nwouldn't\nthe\nof\nneedn\nwere\naren\nin\nwasn't\nfew\nnow\nmustn\ns\ny\nyou're\ntheir\nbeen\nour\ni\nbecause\nnot\nbe\nthen\nagainst\nd\nhaven't\nhis\nagain\nhow\nall\nas\nweren't\nmore\nwouldn\nwill\ninto\nthis\nyou\nshe's\nare\nyourselves\ndidn't\nabove\nown\nneedn't\nwith\nyou'd\nhave\nam\nfurther\nthere\nvery\nnor\ndoesn't\nwhat\ndid\nthat\nwhile\nthem\nsuch\nhadn\nshe\nbetween\nhaving\ncouldn\nhas\na\nwon\nhim\nhere\nit's\nyou've\nat\nshan\nis\nonly\nthey\nll\nours\nbut\nafter\nhasn\nfor\nwhen\ndown\nsame\nor\nyours\nt\nre\nitself","38":"import nltk, re\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\ndef expand_contractions(text):\n    text = re.sub(r\"can't\", \"can not\", text)\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"'s\", \" \", text)\n    text = re.sub(r\"'ve\", \" have \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"'re\", \" are \", text)\n    text = re.sub(r\"'d\", \" would \", text)\n    text = re.sub(r\"'ll\", \" will \", text)\n    return text\n\ndef remove_url(text):\n    URL_REGEX = re.compile(r'''((http[s]?:\/\/)[^ <>'\"{}|\\^`[\\]]*)''')\n    return URL_REGEX.sub(r' ', text)\n\ndef remove_handles(text):\n    HANDLES_REGEX = re.compile(r'@\\S+')\n    return HANDLES_REGEX.sub(r' ', text)\n\ndef remove_incomplete_last_word(text):\n    INCOMPLETE_LAST_WORD_REGEX = re.compile(r'\\S+\u2026')\n    return INCOMPLETE_LAST_WORD_REGEX.sub(r' ', text )\n\nremove_punc = lambda x : re.sub(r\"\\W\", ' ', x)\n\nremove_num = lambda x : re.sub(r\"\\d\", ' ', x)\n\nremove_extra_spaces = lambda x : re.sub(r\"\\s+\", ' ', x)\n\nremove_shortwords = lambda x: ' '.join(word for word in x.split() if len(word) > 2)\n\nlower_case = lambda x : x.lower()\n\nwith open('stopwords.txt') as f:\n    sw = map(lambda x : x.strip(), f.readlines())\nstop_words = set(nltk.corpus.stopwords.words('english'))|set(sw)\nremove_stopwords = lambda x: ' '.join(word for word in x.split() if word not in stop_words)\n\nps = PorterStemmer()\nps_stem = lambda x: ' '.join(ps.stem(word) for word in x.split())\n\nwnl = WordNetLemmatizer()\nwnl_lemmatize = lambda x: ' '.join(wnl.lemmatize(word) for word in x.split())\n\ndef tag_pos(x):\n    tag_list =  nltk.pos_tag(nltk.word_tokenize(x))\n    pos = \"\"\n    for t in tag_list:\n        pos += t[0] +'(' + t[1] +')' + ' '\n    return pos\n\ndef cleanText(x, rsw, stm, lem, tgps):\n    x = str(x)\n    x = remove_url(x)\n    x = lower_case(x)\n    x = expand_contractions(x)\n    x = remove_punc(x)\n    x = remove_num(x)\n    x = remove_extra_spaces(x)\n    x = remove_shortwords(x)\n    \n    if rsw:\n        x = remove_stopwords(x)\n    if stm:\n        x = ps_stem(x)\n    if lem:\n        x = wnl_lemmatize(x)\n    if tgps:\n        x = tag_pos(x)\n    return x","39":"import time, datetime\r\n\r\ndef timestamp():\r\n    ts = time.time()\r\n    st = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d%H%M%S')\r\n    return st","40":"from IPython.display import clear_output\nfor i in range(n):\n    clear_output(wait=True)\n\n    print('Current Progress', i, '\/', n)","41":"function trim(x) {\n    return x.replace(\/^\\s+|\\s+$\/g, '');\n}","42":"try:\n    2*3\nexcept TypeError:\n    print(\"An exception was raised\")\nelse:\n    print(\"Thank God, no exceptions were raised.\")","43":"a, b, *c, d = (1,2,3,4,5)\n\nprint(a) # 1\nprint(b) # 2\nprint(c) # [3,4]\nprint(d) # 5","44":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n\ndef sentiment_scores(sentence): \n    sia_obj = SentimentIntensityAnalyzer() \n    sentiment_dict = sia_obj.polarity_scores(sentence) \n    if sentiment_dict['compound'] >= 0.05 : \n        return 1\n    elif sentiment_dict['compound'] <= - 0.05 : \n        return -1\n    else : \n        return 0","45":"headers = {\n    'User-Agent': 'Mozilla\/5.0 (Windows NT 6.1)'\n}\n\nres = requests.get(url, headers=headers)\nif res.status_code == requests.codes.ok:\n    ressoup = bs4.BeautifulSoup(res.text, 'lxml')\n    elems = ressoup.select('.link')\n    elems[i].getText()\n    elems[i].get('attr')\nelse:\n    print('Something went wrong')","46":"import numpy as np\nimport pandas as pd\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef buildWordCloud(text):\n    wordcloud = WordCloud(width = W, height = H,\n                background_color =BGC,\n                min_font_size = 10,\n                max_words = mw).generate(text)\n    plt.figure(figsize = (W\/\/100, H\/\/100), facecolor = None)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.tight_layout(pad = 0)\n    plt.show()","47":"import xml.etree.ElementTree as etree\ntree = etree.ElementTree(etree.fromstring(xml_string))\nroot = tree.getroot()\nroot.getchildren()\nnode.attrib","48":"# any()\n# This expression returns True if any element of the iterable is true.\n# If the iterable is empty, it will return False.\n\n>>> any([1>0,1==0,1<0])\nTrue\n>>> any([1<0,2<1,3<2])\nFalse\n\n# all()\n# This expression returns True if all of the elements of the iterable are true. \n# If the iterable is empty, it will return True.\n\n>>> all(['a'<'b','b'<'c'])\nTrue\n>>> all(['a'<'b','c'<'b'])\nFalse","49":">>> from collections import Counter\n>>> \n>>> myList = [1,1,2,3,4,5,3,2,3,4,2,1,2,3]\n>>> print Counter(myList)\nCounter({2: 4, 3: 4, 1: 3, 4: 2, 5: 1})\n>>>\n>>> print Counter(myList).items()\n[(1, 3), (2, 4), (3, 4), (4, 2), (5, 1)]\n>>> \n>>> print Counter(myList).keys()\n[1, 2, 3, 4, 5]\n>>> \n>>> print Counter(myList).values()\n[3, 4, 4, 2, 1]","50":">>> from collections import OrderedDict\n>>> \n>>> ordinary_dictionary = {}\n>>> ordinary_dictionary['a'] = 1\n>>> ordinary_dictionary['b'] = 2\n>>> ordinary_dictionary['c'] = 3\n>>> ordinary_dictionary['d'] = 4\n>>> ordinary_dictionary['e'] = 5\n>>> \n>>> print ordinary_dictionary\n{'a': 1, 'c': 3, 'b': 2, 'e': 5, 'd': 4}\n>>> \n>>> ordered_dictionary = OrderedDict()\n>>> ordered_dictionary['a'] = 1\n>>> ordered_dictionary['b'] = 2\n>>> ordered_dictionary['c'] = 3\n>>> ordered_dictionary['d'] = 4\n>>> ordered_dictionary['e'] = 5\n>>> \n>>> print ordered_dictionary\nOrderedDict([('a', 1), ('b', 2), ('c', 3), ('d', 4), ('e', 5)])","51":"# The defaultdict tool is a container in the collections class of Python. \n# It's similar to the usual dictionary (dict) container, \n# but the only difference is that a defaultdict will have a default value if that key has not been set yet. \n# If you didn't use a defaultdict you'd have to check to see if that key exists, \n# and if it doesn't, set it to what you want.\n>>> from collections import defaultdict\n>>> d = defaultdict(list)\n>>> d['python'].append(\"awesome\")\n>>> d['something-else'].append(\"not relevant\")\n>>> d['python'].append(\"language\")\n>>> for i in d.items():\n...     print(i)\n...\n('python', ['awesome', 'language'])\n('something-else', ['not relevant'])","52":">>> from collections import deque\n>>> d = deque()\n>>> d.append(1)\n>>> print d\ndeque([1])\n>>> d.appendleft(2)\n>>> print d\ndeque([2, 1])\n>>> d.clear()\n>>> print d\ndeque([])\n>>> d.extend('1')\n>>> print d\ndeque(['1'])\n>>> d.extendleft('234')\n>>> print d\ndeque(['4', '3', '2', '1'])\n>>> d.count('1')\n1\n>>> d.pop()\n'1'\n>>> print d\ndeque(['4', '3', '2'])\n>>> d.popleft()\n'4'\n>>> print d\ndeque(['3', '2'])\n>>> d.extend('7896')\n>>> print d\ndeque(['3', '2', '7', '8', '9', '6'])\n>>> d.remove('2')\n>>> print d\ndeque(['3', '7', '8', '9', '6'])\n>>> d.reverse()\n>>> print d\ndeque(['6', '9', '8', '7', '3'])\n>>> d.rotate(3)\n>>> print d\ndeque(['8', '7', '3', '6', '9'])","53":">>> from collections import namedtuple\n>>> Point = namedtuple('Point','x,y')\n>>> pt1 = Point(1,2)\n>>> pt2 = Point(3,4)\n>>> dot_product = ( pt1.x * pt2.x ) +( pt1.y * pt2.y )\n>>> print dot_product\n11\n\n>>> from collections import namedtuple\n>>> Car = namedtuple('Car','Price Mileage Colour Class')\n>>> xyz = Car(Price = 100000, Mileage = 30, Colour = 'Cyan', Class = 'Y')\n>>> print xyz\nCar(Price=100000, Mileage=30, Colour='Cyan', Class='Y')\n>>> print xyz.Class\nY","54":"# == tests equality\n# is test identity\n\nl1 = [1,2,3,4]\nl2 = [1,2,3,4]\n\nprint(l1 == l2) # True\nprint(l1 is l2) # False\n\nl3 = l1\nl1[0] = 5\n\nprint(l1 == l3) # True\nprint(l1 is l3) # True\nprint(l1, id(l1))       # [5, 2, 3, 4] 2391232377608\nprint(l3, id(l3))       # [5, 2, 3, 4] 2391232377608","55":">>> from itertools import combinations\n>>> \n>>> print list(combinations('12345',2))\n[('1', '2'), ('1', '3'), ('1', '4'), ('1', '5'), ('2', '3'), ('2', '4'), ('2', '5'), ('3', '4'), ('3', '5'), ('4', '5')]\n>>> \n>>> A = [1,1,3,3,3]\n>>> print list(combinations(A,4))\n[(1, 1, 3, 3), (1, 1, 3, 3), (1, 1, 3, 3), (1, 3, 3, 3), (1, 3, 3, 3)]\n>>> from itertools import combinations_with_replacement\n>>> \n>>> print list(combinations_with_replacement('12345',2))\n[('1', '1'), ('1', '2'), ('1', '3'), ('1', '4'), ('1', '5'), ('2', '2'), ('2', '3'), ('2', '4'), ('2', '5'), ('3', '3'), ('3', '4'), ('3', '5'), ('4', '4'), ('4', '5'), ('5', '5')]\n>>> \n>>> A = [1,1,3,3,3]\n>>> print list(combinations(A,2))\n[(1, 1), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (1, 3), (3, 3), (3, 3), (3, 3)]","56":">>> from itertools import permutations\n>>> print permutations(['1','2','3'])\n<itertools.permutations object at 0x02A45210>\n>>> \n>>> print list(permutations(['1','2','3']))\n[('1', '2', '3'), ('1', '3', '2'), ('2', '1', '3'), ('2', '3', '1'), ('3', '1', '2'), ('3', '2', '1')]\n>>> \n>>> print list(permutations(['1','2','3'],2))\n[('1', '2'), ('1', '3'), ('2', '1'), ('2', '3'), ('3', '1'), ('3', '2')]\n>>>\n>>> print list(permutations('abc',3))\n[('a', 'b', 'c'), ('a', 'c', 'b'), ('b', 'a', 'c'), ('b', 'c', 'a'), ('c', 'a', 'b'), ('c', 'b', 'a')]","57":">>> from itertools import product\n>>>\n>>> print list(product([1,2,3],repeat = 2))\n[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]\n>>>\n>>> print list(product([1,2,3],[3,4]))\n[(1, 3), (1, 4), (2, 3), (2, 4), (3, 3), (3, 4)]\n>>>\n>>> A = [[1,2,3],[3,4,5]]\n>>> print list(product(*A))\n[(1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 3), (3, 4), (3, 5)]\n>>>\n>>> B = [[1,2,3],[3,4,5],[7,8]]\n>>> print list(product(*B))\n[(1, 3, 7), (1, 3, 8), (1, 4, 7), (1, 4, 8), (1, 5, 7), (1, 5, 8), (2, 3, 7), (2, 3, 8), (2, 4, 7), (2, 4, 8), (2, 5, 7), (2, 5, 8), (3, 3, 7), (3, 3, 8), (3, 4, 7), (3, 4, 8), (3, 5, 7), (3, 5, 8)]","58":">>> import re\n>>> re.findall(r'\\w','http:\/\/www.hackerrank.com\/')\n['h', 't', 't', 'p', 'w', 'w', 'w', 'h', 'a', 'c', 'k', 'e', 'r', 'r', 'a', 'n', 'k', 'c', 'o', 'm']\n\n>>> import re\n>>> re.finditer(r'\\w','http:\/\/www.hackerrank.com\/')\n<callable-iterator object at 0x0266C790>\n>>> map(lambda x: x.group(),re.finditer(r'\\w','http:\/\/www.hackerrank.com\/'))\n['h', 't', 't', 'p', 'w', 'w', 'w', 'h', 'a', 'c', 'k', 'e', 'r', 'r', 'a', 'n', 'k', 'c', 'o', 'm']","59":">>> import re\n>>> m = re.match(r'(\\w+)@(\\w+)\\.(\\w+)','username@hackerrank.com')\n>>> m.group(0)       # The entire match \n'username@hackerrank.com'\n>>> m.group(1)       # The first parenthesized subgroup.\n'username'\n>>> m.group(2)       # The second parenthesized subgroup.\n'hackerrank'\n>>> m.group(3)       # The third parenthesized subgroup.\n'com'\n>>> m.group(1,2,3)   # Multiple arguments give us a tuple.\n('username', 'hackerrank', 'com')\n\n>>> import re\n>>> m = re.match(r'(\\w+)@(\\w+)\\.(\\w+)','username@hackerrank.com')\n>>> m.groups()\n('username', 'hackerrank', 'com')\n\n>>> m = re.match(r'(?P<user>\\w+)@(?P<website>\\w+)\\.(?P<extension>\\w+)','myname@hackerrank.com')\n>>> m.groupdict()\n{'website': 'hackerrank', 'user': 'myname', 'extension': 'com'}"}}